style: PEP
language: python
files:
  - "src/**/*.py"
functions:
  - "*"
ignore_files:
  - "**/test_*.py"       # Ignore all test files
  - "**/__init__.py"     # Ignore __init__.py files

llm_config:

  mode: LOCAL

  temperature: 0.25         
  max_tokens_per_response: 2048 

  local:
    model_path: !ENV DOCMANCER_MODEL_PATH 
    n_gpu_layers: -1      
    n_ctx: 4096           
    n_batch: 512 

  remote_api:
    provider: some-llm
    api_endpoint: "http://127.0.0.1:8000/v1/chat/completions" # Example API endpoint
    api_key: abc-123     # Example API key
    headers:
      Authorization: "Bearer ${api_key}"
      Custom-Header: "value"
    payload_template:
      model: "llm-v1"
      messages: "${messages}"
      max_tokens: 1024
      temperature: 0.7
    response_path: "choices.0.message.content"