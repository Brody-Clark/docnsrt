vars:
  API_KEY: !ENV API_KEY  # Store environment variable TEST_API_KEY in reusable variable API_KEY
log_level: INFO
style: PEP
language: python
files:
  - "src/**/*.py"
functions:
  - "*"
ignore_files:
  - "**/test_*.py"       # Ignore all test files
  - "**/__init__.py"     # Ignore __init__.py files

llm_config:

  mode: REMOTE_API
  temperature: 0.25 
  max_tokens_per_response: 2048 

  # local:
  #   model_path: !ENV MODEL_PATH  # Path to local model
  #   n_gpu_layers: 20
  #   n_ctx: 30000
  #   n_batch: 512
  remote_api:
    provider: some-llm
    api_endpoint: "http://127.0.0.1:8000/v1/chat/completions" # Example API endpoint
    headers:
      Authorization: "Bearer ${vars.API_KEY}"
      Custom-Header: "value"
    payload_template:
      model: "llm-v1"
      messages: 
        - role: "user"
          content: "${prompt}"
      max_tokens: 1024
    response_path: "choices.0.message.content"
    track_tokens_and_cost: true
    